

《现代控制理论》
课程论文


题    目：      人工智能与人工神经网络                  　　
学生姓名：   朱高明         学号：1120170721          
院 （系）： 信息工程学院    专业班级： 软件工程      　   　　　   
 
 
  



2017年12月22日
人工智能与人工神经网络
摘要：控制理论从提出到目前为止，共经历了三个重大的发展时期，别是经典控制理论、现代控制理论和智能控制理论。智能控制属于较新的控制理论，现在主要用于人工智能领域。人工智能一直处于计算机技术的前沿，人工智能研究的理论和发现在很大程度上将决定计算机技术的发展方向。而神经网络则是人工智能领域不可或缺的一部分，为了使更多的人了解到人工智能，推动控制理论的不断前进，就需要对神经网络进行不断深入探究，本文主要对人工神经网络进行论述。
关键词：控制理论，人工智能，人工神经网络
一、引言
近些年来，伴随着计算机计算能力的不断升级，很多原来只有在科幻电影里才有的桥段越来越多地出现在我们身边了，并给了我们更多的想象空间与期待。
　　在2016年，人工智能界最令人瞩目的事情莫过于谷歌的AlphaGo以4:1的悬殊比分轻松击败韩国著名九段围棋大师李世石。之后化名“Master”的AlphaGo更是一路大开杀戒，分别在对弈网站“弈城”和“腾讯围棋”登录，先后打败了柯洁九段、朴廷桓九段、陈耀烨九段以及创造日本大满贯传奇的井山裕太和亚洲杯冠军李钦诚等世界一流高手，取得了50胜0负的战绩。当然了，“玩不起”的人类最终觉得让AlphaGo在国际围棋网站排名上占一个坑来碾压人类是非常“不公平”的事情，最终把人家给拉黑了。
　　人类这么做是不是有违人工智能研究的初衷暂且不讨论，毕竟我们的眼光还是应该更多地投向那些“更有趣”的领域。除此之外，还有很多非常有趣的人工智能项目也经常在网络视频中带给我们惊喜，比如谷歌的机械狗、谷歌的无人驾驶汽车等。
　　值得一提的是，谷歌的这种机械狗很有趣，除了能够彼此之间互相协调进行编队行进以外，还能像真的狗一样在被踢了一脚之后迅速调整重心，并在短暂的踉跄后站稳，然后继续先前作业，不过怎么踢都不会来咬你。
　　而谷歌的无人驾驶汽车也有着非常优异的能力，到2015年11月底为止，根据谷歌提交给机动车辆管理局的报告，谷歌的无人驾驶汽车在自动模式下已经完成了130多万英里的里程。可以说，这些事情都在鼓舞着我们这些对未来世界充满渴望的人投入更多的精力去研究人工智能带来的新惊喜。
二、人工智能综述
人工智能现状
人工智能即AI，其英文全称为Artificial Intelligence。人工智能的概念要从人工和智能两方面来了解，所谓人工就是指人工智能脱胎于人类的文明，是人类智慧的产物；而智能则是指具有人工智能的计算机或其他子设备可以模拟人类的智能行为和思维方式，人工智能是计算机科学的一个分支，它的近期主要目标在于研究用机器来模仿和执行人脑的某些智能功能，并开发相关理论和技术。 
如今的人工智能机器，可以在胜任一些复杂脑力劳动的同时，辅助人类进行记忆和逻辑运算等活动。现阶段学者已经研制出了一些可以模拟人类精神活动的电子机器，经过完善升级，这些电子机器将有希望超越人类的能力，协助人类完成一些执行难度较大的工作。但是目前研制出的自动化系统或者机器人虽然可以代替部分人类劳动，却还没有到达可以实现人类多方面协调和自我学习升级的智能水平，要制造出一款可以完全拥有人类智慧的机器，还需进一步深入研究。还有一些人工智能产物经常应用于各种商业用途，例如单位内部的客户信息系统，决策支持系统，以及我们在世面上可以看见的医学顾问、法津顾问等软件。
深度学习 
人工智能这一领域中最为核心的内容之一就是深度学习。深度学习现在在全世界范围内都有着众多的专业工作者和业余爱好者在进行着研究，并且每个月都有不少新的落地产品问世。应该说，深度学习是目前世界上最热门的研究领域之一，而且也是未来几十年最热门的研究方向之一。
　　在中国，深度学习也有着众多的专业研究机构和业余爱好者，他们非常渴望了解深度学习的知识并加以应用。但是，深度学习由于其本身的复杂性，使得很多有着浓厚兴趣的爱好者望而却步，我认为主要的门槛来自于两个方面。
　　一方面，深度学习是非常典型的计算密集型的应用领域，家用PC机通常是无法有效胜任一个完整而可靠的深度学习应用的（作为初级实验或者“玩具”的除外）。不过现在随着CPU的计算速度逐步加快，以及GPU应用的不断普及，这方面的门槛在慢慢地降低。
　　另一方面，深度学习从其解决问题的根本理论方面需要比较深厚和扎实的数学基础，尤其是高等数学、线性代数、泛函分析及其延伸学科的基础，这就使得很多高等数学相关基础不好的朋友学习起来非常吃力。当然，这一方面目前可以走的捷径也不是没有，我们可以通过现成的框架（比如TensorFlow、Torch、Caffe或Theano等）来搭建环境，并用简单的代码或模型描述文件来组建一个相对完整的神经网络进行学习和分类应用。
　　除此之外，像Caffe还有一个叫做Model Zoo的共享社群——这是一个让大家把已经训练好的模型放在上面做共享的社群。在模型训练中，前面大量耗时的分析和建模工作以及训练后得到的最宝贵的模型成果就可以浓缩并沉淀为一个可下载的模型描述文件，里面是网络的节点权重和拓扑结构信息。这种社群化的方式会让很多原本没有太好训练条件的朋友有了可以学习和借鉴的对象，也有了可以游乐和尝试的空间。这些模型需要在其各自的授权使用协议下合理使用，有的是允许进行商业应用和改动，而有的则不可以，这一点需要注意。在下载后，我们可以对其进行Fine Tuning，也就是进行细节调优或改进性训练，使得这些模型可以在自己需要的环境和条件下更好地工作。不过这个地方还是有一个门槛，对于很多数学能力欠佳的工程师来说，不容易迈过去，那就是训练和调优中的方向性问题。一旦出现召回率和准确率不再提高，或者性能等问题，往往会找不到改进的方向和方法，这是需要扎实的数学基础和深度学习领域的实践经验来解决的。
人工智能一直处于计算机技术的前沿，人工智能研究的理论和发现在很大程度上将决定计算机技术的发展方向。今天，已经有很多人工智能研究的成果进入人们的日常生活。将来，人工智能技术的发展将会给人们的生活、工作和教育等带来更大的影响。
三、人工神经网络
控制理论从提出到目前为止，共经历了三个重大的发展时期，别是经典控制理论、现代控制理论和智能控制理论。智能控制属于较新的控制理论，现在主要用于人工智能领域。为了使更多的人了解到人工智能，推动控制理论的不断前进，就需要对神经网络进行不断深入了解。因为神经网络是人工智能领域不可或缺的部分，下面将对人工神经网络展开论述。
神经元的提出
“人工神经网络”(ARTIFICIAL NEURAL NETWORK，简称A.N.N.)是在对人脑组织结构和运行机智的认识理解基础之上模拟其结构和智能行为的一种工程系统。早在本世纪40年代初期，心理学家McCulloch、数学家Pitts就提出了人工神经网络的第一个数学模型，从此开创了神经科学理论的研究时代。其后，F.Rosenblatt、Widrow和Hopf、J.J.Hopfield等学者又先后提出了感知模型，使得人工神经网络技术得以蓬勃发展。神经系统的基本构造是神经元(神经细胞)，它是处理人体内各部分之间相互信息传递的基本单元。		
每个神经元都由一个细胞体，一个连接其他神经元的轴突和一些向外伸出的其它较短分支——树突组成。轴突的功能是将本神经元的输出信号(兴奋)传递给别的神经元。其末端的许多神经末梢使得兴奋可以同时传送给多个神经元。树突的功能是接受来自其它神经元的兴奋。神经元细胞体将接受到的所有信号进行简单地处理(如：加权求和，即对所有的输入信号都加以考虑且对每个信号的重视程度——体现在权值上——有所不同)后由轴突输出。神经元的树突与另外的神经元的神经末梢相连的部分称为突触。我们知道，大脑之所以能够处理极其复杂的分析、推理工作，一方面是因为其神经元个数的庞大，另一方面还在于神经元能够对输入信号进行非线性处理。因此，我们可以建立起更接近于工程的神经元的数学模型，如下图1所示，它是一个多输入单输出的非线性器件。其中的权值w即代表神经元之间的连接强度，f为非线性函数。
 
图1.神经元数学模型
人工神经网络的工作原理
人工神经网络首先要以一定的学习准则进行学习，然后才能工作。现以人工神经网络对手写“A”、“B”两个字母的识别为例进行说明，规定当“A”输入网络时，应该输出“1”，而当输入为“B”时，输出为“0”。所以网络学习的准则应该是：如果网络作出错误的的判决，则通过网络的学习，应使得网络减少下次犯同样错误的可能性。首先，给网络的各连接权值赋予(0，1)区间内的随机值，将“A”所对应的图象模式输入给网络，网络将输入模式加权求和、与门限比较、再进行非线性运算，得到网络的输出。在此情况下，网络输出为“1”和“0”的概率各为50%，也就是说是完全随机的。这时如果输出为“1”(结果正确)，则使连接权值增大，以便使网络再次遇到“A”模式输入时，仍然能作出正确的判断。如果输出为“0”(即结果错误)，则把网络连接权值朝着减小综合输入加权值的方向调整，其目的在于使网络下次再遇到“A”模式输入时，减小犯同样错误的可能性。如此操作调整，当给网络轮番输入若干个手写字母“A”、“B”后，经过网络按以上学习方法进行若干次学习后，网络判断的正确率将大大提高。这说明网络对这两个模式的学习已经获得了成功，它已将这两个模式分布地记忆在网络的各个连接权值上。当网络再次遇到其中任何一个模式时，能够作出迅速、准确的判断和识别。一般说来，网络中所含的神经元个数越多，则它能记忆、识别的模式也就越多。
人工神经网络的特点
人工神经网络是由大量处理单元互联组成的非线性、自适应信息处理系统。它是在现代神经科学研究成果的基础上提出的，试图通过模拟大脑神经网络处理、记忆信息的方式进行信息处理。人工神经网络具有以下四个基本特征：
1)	非线性
非线性关系是自然界的普遍特性。大脑的智慧就是一种非线性现象。人工神经元处于激活或抑制二种不同的状态，这种行为在数学上表现为一种非线性关系。具有阈值的神经元构成的网络具有更好的性能，可以提高容错性和存储容量。
2)	非局限性
一个神经网络通常由多个神经元广泛连接而成。一个系统的整体行为不仅取决于单个神经元的特征，而且可能主要由单元之间的相互作用、相互连接所决定。通过单元之间的大量连接模拟大脑的非局限性。联想记忆是非局限性的典型例子。
3)	非常定性
人工神经网络具有自适应、自组织、自学习能力。神经网络不但处理的信息可以有各种变化，而且在处理信息的同时，非线性动力系统本身也在不断变化。经常采用迭代过程描写动力系统的演化过程。
4)	非凸性
一个系统的演化方向，在一定条件下将取决于某个特定的状态函数。例如能量函数，它的极值相应于系统比较稳定的状态。非凸性是指这种函数有多个极值，故系统具有多个较稳定的平衡态，这将导致系统演化的多样性。
人工神经网络中，神经元处理单元可表示不同的对象，例如特征、字母、概念，或者一些有意义的抽象模式。网络中处理单元的类型分为三类：输入单元、输出单元和隐单元。输入单元接受外部世界的信号与数据；输出单元实现系统处理结果的输出；隐单元是处在输入和输出单元之间，不能由系统外部观察的单元。神经元间的连接权值反映了单元间的连接强度，信息的表示和处理体现在网络处理单元的连接关系中。人工神经网络是一种非程序化、适应性、大脑风格的信息处理 ，其本质是通过网络的变换和动力学行为得到一种并行分布式的信息处理功能，并在不同程度和层次上模仿人脑神经系统的信息处理功能。它是涉及神经科学、思维科学、人工智能、计算机科学等多个领域的交叉学科。
人工神经网络是并行分布式系统，采用了与传统人工智能和信息处理技术完全不同的机理，克服了传统的基于逻辑符号的人工智能在处理直觉、非结构化信息方面的缺陷，具有自适应、自组织和实时学习的特点。
人工神经网络的特点和优越性，主要表现在以下三个方面：
第一，具有自学习功能。例如实现图像识别时，只在先把许多不同的图像样板和对应的应识别的结果输入人工神经网络，网络就会通过自学习功能，慢慢学会识别类似的图像。自学习功能对于预测有特别重要的意义。预期未来的人工神经网络计算机将为人类提供经济预测、市场预测、效益预测，其应用前途是很远大的。
第二，具有联想存储功能。用人工神经网络的反馈网络就可以实现这种联想。
第三，具有高速寻找优化解的能力。寻找一个复杂问题的优化解，往往需要很大的计算量，利用一个针对某问题而设计的反馈型人工神经网络，发挥计算机的高速运算能力，可能很快找到优化解。
我们应当明白，人工神经网络同现行的计算机不同，它是一种非线性的处理单元。只有当神经元对所有的输入信号的综合处理结果超过某一门限值后才输出一个信号。因此神经网络是一种具有高度非线性的超大规模连续时间动力学系统。它突破了传统的以线性处理为基础的数字电子计算机的局限，标志着人们智能信息处理能力和模拟人脑智能行为能力的一大飞跃。 
几种典型的神经网络简介
	（1）多层感知网络
在1986年以Rumelhart和McCelland为首的科学家出版的《Parallel Distributed Processing》一书中，完整地提出了误差逆传播学习算法，并被广泛接受。多层感知网络是一种具有三层或三层以上的阶层型神经网络。典型的多层感知网络是三层、前馈的阶层网络，即：输入层I、隐含层(也称中间层)J、输出层K，如下图2所示。相邻层之间的各神经元实现全连接，即下一层的每一个神经元与上一层的每个神经元都实现全连接，而且每层各神经元之间无连接。
  
图2.三层感知网络模型 
学习规则及过程：它以一种有教师示教的方式进行学习。首先由教师对每一种输入模式设定一个期望输出值。然后对网络输入实际的学习记忆模式，并由输入层经中间层向输出层传播(称为“模式顺传播”)。实际输出与期望输出的差即是误差。按照误差平方最小这一规则，由输出层往中间层逐层修正连接权值，此过程称为“误差逆传播”。所以误差逆传播神经网络也简称BP(Back Propagation)网。随着“模式顺传播”和“误差逆传播”过程的交替反复进行。网络的实际输出逐渐向各自所对应的期望输出逼近，网络对输入模式的响应的正确率也不断上升。通过此学习过程，确定下来各层间的连接权值之后就可以工作了。 
    由于BP网及误差逆传播算法具有中间隐含层并有相应的学习规则可寻，使得它具有对非线性模式的识别能力。特别是其数学意义明确、步骤分明的学习算法，更使其具有广泛的应用前景。目前，在手写字体的识别、语音识别、文本——语言转换、图象识别以及生物医学信号处理方面已有实际的应用。 
    但BP网并不是十分的完善，它存在以下一些主要缺陷：学习收敛速度太慢、网络的学习记忆具有不稳定性，即：当给一个训练好的网提供新的学习记忆模式时，将使已有的连接权值被打乱，导致已记忆的学习模式的信息的消失。
    （2）竞争型(KOHONEN)神经网络
它是基于人的视网膜及大脑皮层对剌激的反应而引出的。神经生物学的研究结果表明：生物视网膜中，有许多特定的细胞，对特定的图形(输入模式)比较敏感，并使得大脑皮层中的特定细胞产生大的兴奋，而其相邻的神经细胞的兴奋程度被抑制。对于某一个输入模式，通过竞争在输出层中只激活一个相应的输出神经元。许多输入模式，在输出层中将激活许多个神经元，从而形成一个反映输入数据的“特征图形”。
竞争型神经网络是一种以无教师方式进行网络训练的网络。它通过自身训练，自动对输入模式进行分类。竞争型神经网络及其学习规则与其它类型的神经网络和学习规则相比，有其自己的鲜明特点。在网络结构上，它既不象阶层型神经网络那样各层神经元之间只有单向连接，也不象全连接型网络那样在网络结构上没有明显的层次界限。它一般是由输入层(模拟视网膜神经元)和竞争层(模拟大脑皮层神经元，也叫输出层)构成的两层网络。两层之间的各神经元实现双向全连接，而且网络中没有隐含层，如图下3所示。
 
图3 KOHONEN神经网络结构图
有时竞争层各神经元之间还存在横向连接。竞争型神经网络的基本思想是网络竞争层各神经元竞争对输入模式的响应机会，最后仅有一个神经元成为竞争的胜者，并且只将与获胜神经元有关的各连接权值进行修正，使之朝着更有利于它竞争的方向调整。神经网络工作时，对于某一输入模式，网络中与该模式最相近的学习输入模式相对应的竞争层神经元将有最大的输出值，即以竞争层获胜神经元来表示分类结果。这是通过竞争得以实现的，实际上也就是网络回忆联想的过程。  
    除了竞争的方法外，还有通过抑制手段获取胜利的方法，即网络竞争层各神经元抑制所有其它神经元对输入模式的响应机会，从而使自己“脱颖而出”，成为获胜神经元。除此之外还有一种称为侧抑制的方法，即每个神经元只抑制与自己邻近的神经元，而对远离自己的神经元不抑制。这种方法常常用于图象边缘处理，解决图象边缘的缺陷问题。 
    竞争型神经网络的缺点和不足：因为它仅以输出层中的单个神经元代表某一类模式。所以一旦输出层中的某个输出神经元损坏，则导致该神经元所代表的该模式信息全部丢失。 
    (3)Hopfield神经网络
1986年美国物理学家J.J.Hopfield陆续发表几篇论文，提出了Hopfield神经网络。他利用非线性动力学系统理论中的能量函数方法研究反馈人工神经网络的稳定性，并利用此方法建立求解优化计算问题的系统方程式。基本的Hopfield神经网络是一个由非线性元件构成的全连接型单层反馈系统，网络中的每一个神经元都将自己的输出通过连接权传送给所有其它神经元，同时又都接收所有其它神经元传递过来的信息。即：网络中的神经元t时刻的输出状态实际上间接地与自己的t-1时刻的输出状态有关。所以Hopfield神经网络是一个反馈型的网络。其状态变化可以用差分方程来表征。反馈型网络的一个重要特点就是它具有稳定状态。当网络达到稳定状态的时候，也就是它的能量函数达到最小的时候。这里的能量函数不是物理意义上的能量函数，而是在表达形式上与物理意义上的能量概念一致，表征网络状态的变化趋势，并可以依据Hopfield工作运行规则不断进行状态变化，最终能够达到的某个极小值的目标函数。网络收敛就是指能量函数达到极小值。如果把一个最优化问题的目标函数转换成网络的能量函数，把问题的变量对应于网络的状态，那么Hopfield神经网络就能够用于解决优化组合问题。 
    Hopfield神经网络的能量函数是朝着梯度减小的方向变化，但它仍然存在一个问题，那就是一旦能量函数陷入到局部极小值，它将不能自动跳出局部极小点，到达全局最小点，因而无法求得网络最优解。这可以通过模拟退火算法或遗传算法得以解决，在此不再一一介绍。 
四、总结
人工智能研究的理论和发现在很大程度上将决定计算机技术的发展方向。而神经网络则是人工智能领域不可或缺的一部分，目前，人工神经网络的研究内容相当广泛，反映了多学科交叉技术领域的特点。迄今为止，在人工神经网络研究领域中，有代表性的网络模型已达数十种，而学习算法的类型更难以统计其数量。神经网络研究热潮的兴起是本世纪末人类科学技术发展全面飞跃的一个组成部分。它与多种科学领域的发展密切相关，纵观当代新兴科学技术的发展历史，人类在征服宇宙空间、基本粒子、生命起源等科学领域的进程之中历经了崎岖不平之路。我们也会看到，探索人脑功能和神经网络的研究将伴随着重重困难的克服而日新月异。
参考文献：
[1] 刘肖楠.神经网络在人工智能中的应用[J].信息技术与信息化,2015(01):135-136.
[2] 高扬.白话深度学习与TensorFlow[M].北京：机械工业出版社，2016.
[3] 李红超. 关于人工神经网络的应用研究[J].  电脑知识与技术. 2014(06)
[4] https://baike.so.com/doc/345288-5660715.html



